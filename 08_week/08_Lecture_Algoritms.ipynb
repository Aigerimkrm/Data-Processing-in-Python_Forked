{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture: Algorithmic problem solving\n",
    "\n",
    "November 19, 2024\n",
    "\n",
    "**Algorithmic Thinking for Data Processing in Python**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Goals: Why Algorithms Are Essential**\n",
    "\n",
    "**Why do we need algorithms?**\n",
    "\n",
    "Algorithms are the cornerstone of computation. They allow us to systematically solve problems by defining **how to go from input to output**. Let’s use an analogy:\n",
    "\n",
    "- Think of a **recipe for baking a cake**:\n",
    "    - The ingredients are your **input** (flour, sugar, eggs, etc.).\n",
    "    - The baked cake is your **output**.\n",
    "    - The recipe itself is the **algorithm**: a step-by-step guide for achieving the desired result.\n",
    "\n",
    "Now, imagine baking for 1,000 people instead of 10. Without careful planning (efficient algorithms), the process becomes chaotic and inefficient. Similarly, in data analysis, algorithms ensure our solutions scale well with large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Characteristics of Algorithms:**\n",
    "\n",
    "1. **Correctness:**\n",
    "    \n",
    "    An algorithm must consistently produce the right output. If it’s a sorting algorithm, the output should always be sorted.\n",
    "      - *Think of a navigation app like Google Maps. Correctness!*\n",
    "  \n",
    "2. **Efficiency:**\n",
    "    \n",
    "    Algorithms should use resources wisely, especially time and memory. Efficiency ensures solutions remain practical as input size grows.\n",
    "    - **Intuition:** A slow algorithm is like being stuck in traffic; an efficient one takes the fastest possible route to your destination.\n",
    "\n",
    "An **algorithm** is more than just code; it’s a logical procedure that works in any context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem:\n",
    "\n",
    "**Algorithms often solve a mapping problem**:\n",
    "\n",
    "- Set of inputs → space of outputs (m → n) mapping.\n",
    "- Binary relation between inputs and outputs, not necessarily strictly bijection (one-to-one).\n",
    "- Specify a predicate: Are there two people with the same birthday in the class today?\n",
    "\n",
    "- Mathematic problems - Scientific computing:\n",
    "    - What is the derivative of $x^2$ at $x=1$?\n",
    "- The algorithm should be general enough to apply to, say, C2 functions.\n",
    "    - Apply to arbitrarily large inputs.\n",
    "\n",
    "\n",
    "- **Input → Output:** A function that transforms data into the desired result.\n",
    "    - *Example:* Input = birthdays of people; Output = whether any two people share the same birthday.\n",
    "\n",
    "**Generalization and Abstraction:**\n",
    "\n",
    "- Good algorithms aren’t limited to specific cases; they generalize to handle **any input size** or **any variation of the problem**.\n",
    "    - For instance, checking for shared birthdays in a small class of 10 versus a company of 10,000 people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm:\n",
    "\n",
    "- Procedure (function) generating outputs, ideally correct outputs.\n",
    "- m -> 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question:\n",
    "\n",
    "- Devise an algorithm that finds out if two people have the same birthday.\n",
    "- Do you know any famous algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Birthday Problem\n",
    "\n",
    "The **birthday problem** asks if any two people in a group share the same birthday.\n",
    "\n",
    "**Why is this interesting?**\n",
    "\n",
    "- If the group has 366 people, it’s obvious someone must share a birthday (pigeonhole principle).\n",
    "- But surprisingly, with just **23 people**, there’s a 50% chance of a shared birthday.\n",
    "\n",
    "Why does this happen?\n",
    "\n",
    "- As the group grows, the number of comparisons increases quadratically (pairs of birthdays). This makes the problem computationally challenging for large groups unless we design an efficient algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Designing the Birthday Problem Algorithm\n",
    "\n",
    "**Problem Restatement:**\n",
    "\n",
    "Given a list of birthdays, find if any two are the same.\n",
    "\n",
    "**Two Solutions:**\n",
    "\n",
    "1. **Naive Approach (Inefficient):**\n",
    "    - Compare every birthday with every other birthday.\n",
    "    - Time complexity: $O(n^2)$.\n",
    "    - A classroom setting where you ask each student their birthday and compare it manually with everyone else.\n",
    "    \n",
    "2. **Optimized Approach (Using Sets):**\n",
    "    - Use a set to track seen birthdays.\n",
    "    - For each birthday:\n",
    "        - If it’s already in the set, return `True`.\n",
    "        - Otherwise, add it to the set.\n",
    "    - Time complexity: $O(n)$.\n",
    "    - Instead of comparing everyone in the class, imagine writing down birthdays on sticky notes. If a birthday comes up twice, you instantly spot the duplicate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_duplicate_birthdays(birthdays):\n",
    "    seen = set()\n",
    "    for birthday in birthdays:\n",
    "        if birthday in seen:\n",
    "            return True\n",
    "        seen.add(birthday)\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Why is this efficient? Membership checks in a set are $O(1)$, so the overall time complexity is linear relative to the number of birthdays.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "CPU times: user 251 μs, sys: 99 μs, total: 350 μs\n",
      "Wall time: 313 μs\n"
     ]
    }
   ],
   "source": [
    "# random 20 birthdays in date format\n",
    "birthdays = [\"01-01\", \"02-14\", \"03-15\", \"01-01\", \"02-22\", \"08-07\", \"12-25\", \"01-01\", \"02-14\", \"03-15\", \"01-01\", \"02-22\", \"08-07\", \"12-25\", \"01-01\", \"02-14\", \"03-15\", \"01-01\", \"02-22\", \"08-07\"]\n",
    "\n",
    "%time print(has_duplicate_birthdays(birthdays))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Efficiency and Complexity**\n",
    "\n",
    "**How do we measure efficiency?**\n",
    "\n",
    "- Instead of time in seconds, we count the **number of fundamental operations** the algorithm performs as the input size $(n)$ grows. This is called **asymptotic analysis**.\n",
    "\n",
    "- *\"How quickly the runtime grows relative to the input data to be processed by that algorithm.\"*\n",
    "\n",
    "- Abstract sense, not seconds or hours\n",
    "- Does not even need to be connected to the implementation - certain tasks has certain efficiency\n",
    "- Exact performance depends on size of the input space (birthday problem for 10 or 1000 people in class)\n",
    "- The most efficient $O(1)$ access of item in dictionary\n",
    "- The least efficient $O(n!)$\n",
    "  - Traveling Salesman Problem (**TSP**): The TSP involves finding the shortest possible route that visits a set of cities and returns to the origin city. A brute force approach, which tries every possible permutation to find the shortest tour, has a time complexity of $O(n!)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Big-O Complexity: Intuitive Examples**\n",
    "\n",
    "1. **Constant Time ($O(1)$):**\n",
    "    - Retrieving an item from a dictionary.\n",
    "    - **Analogy:** Finding a book by its exact shelf number in a library.\n",
    "2. **Linear Time ($O(n)$):**\n",
    "    - Iterating through a list of $n$ items.\n",
    "    - **Analogy:** Flipping through the pages of a book.\n",
    "3. **Quadratic Time ($O(n^2)$):**\n",
    "    - Comparing every item in a list with every other item.\n",
    "    - **Analogy:** Comparing all pairs of students in a classroom.\n",
    "4. **Factorial Time ($O(n!)$):**\n",
    "    - Checking all possible orders of $n$ items.  \n",
    "    - **Analogy:** Arranging 10 books on a shelf in every possible order.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"big_o_time.png\" width=600px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traveling Salesman Problem (TSP)\n",
    "\n",
    "The **Traveling Salesman Problem** (TSP) is a famous optimization problem:\n",
    "\n",
    "- **Statement:** A salesman needs to visit $n$ cities and return to the starting city, minimizing the total distance traveled.    \n",
    "\n",
    "*\"Given a list of cities and the distances between each pair of cities, what is the shortest possible route that visits each city exactly once and returns to the origin city?\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why is TSP hard?**\n",
    "\n",
    "- For $n=4$, there are $3! =6$ possible routes.\n",
    "    \n",
    "- For $n=10$, there are $9 ! =362,880$ routes.\n",
    "    \n",
    "- For $n=20$, there are $19! =1.2×1018$ routes—this is infeasible to compute by brute force.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Intuition:**\n",
    "\n",
    "- TSP is computationally expensive because the number of possibilities grows **factorially**.\n",
    "- **Why do we care?** TSP models real-world logistics, such as optimizing delivery routes or supply chain management.\n",
    "\n",
    "**Efficient Solutions:**\n",
    "\n",
    "- Exact algorithms like **dynamic programming** can solve TSP for small $n$.\n",
    "\n",
    "- Heuristics (e.g., **nearest neighbor**) approximate solutions for larger $n$, often with good results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Us: Breaking Down Complex Problems\n",
    "\n",
    "**Why is breaking down problems important?**\n",
    "\n",
    "**Divide and Conquer:**\n",
    "\n",
    "- Break large problems into smaller sub-problems. For example:\n",
    "    - Instead of analyzing a large dataset all at once, split it into chunks, process each independently, and combine results.\n",
    "\n",
    "- **Intuition:** Solving a big problem is like eating an elephant—it’s only possible one bite at a time. By breaking the problem into smaller sub-problems, we make it manageable.\n",
    "\n",
    "**Practical Tips for Algorithmic Problem Solving:**\n",
    "\n",
    "1. **Start Small:** Solve the problem for a minimal input size first (e.g., 2 people).\n",
    "2. **Generalize:** Identify patterns that work for larger inputs.\n",
    "3. **Test Edge Cases:** Handle unexpected inputs, like empty lists or extreme values.\n",
    "\n",
    "**Efficient Data Structures:**\n",
    "\n",
    "The choice of data structure impacts efficiency:\n",
    "   - Lists: Simple but inefficient for lookups ($O(n)$).\n",
    "   - Sets/Dictionaries: Excellent for membership testing ($O(1)$).\n",
    "   - Pandas DataFrames: Built-in optimizations for data manipulation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We use Built-In Libraries:\n",
    "\n",
    "Python provides robust libraries, such as `pandas` and `numpy`, which already implement efficient algorithms. Use them whenever possible to avoid reinventing the wheel.\n",
    "\n",
    "Practical Implementation:\n",
    "In pandas, we can use the `.duplicated(`) method to find duplicates in a dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "CPU times: user 727 μs, sys: 169 μs, total: 896 μs\n",
      "Wall time: 788 μs\n"
     ]
    }
   ],
   "source": [
    "# birthday data with duplicates in pandas\n",
    "data = pd.DataFrame({'Birthdays': [\"01-01\", \"02-14\", \"03-15\", \"01-01\"]})\n",
    "# duplicates_exist = data['Birthdays'].duplicated().any()\n",
    "\n",
    "%time print(data['Birthdays'].duplicated().any())  # Output: True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Takeaways\n",
    "\n",
    "1. **Algorithmic Thinking:**\n",
    "    \n",
    "    Approach problems systematically. Break them into steps, use the right data structures, and analyze efficiency.\n",
    "    \n",
    "2. **Efficiency Awareness:**\n",
    "    \n",
    "    Evaluate algorithms based on complexity ($O(n)$, $O(n^2)$, etc.), not just speed on a specific computer.\n",
    "    \n",
    "3. **Practical Relevance:**\n",
    "    \n",
    "    Problems like TSP and the birthday problem show how theory translates into real-world applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Bubble Sort\n",
    "\n",
    "### Concept\n",
    "\n",
    "Bubble Sort is a simple sorting algorithm. It repeatedly steps through the list, \n",
    "compares each pair of adjacent items, and swaps them if they are in the wrong order. \n",
    "The process is repeated until no more swaps are needed, indicating that the list is sorted.\n",
    "\n",
    "### Process\n",
    "\n",
    "1. **Start at the beginning** of the list.\n",
    "2. **Compare the first two elements**. If the first is greater than the second, swap them.\n",
    "3. **Move to the next pair** of elements, repeat the comparison and swap if necessary.\n",
    "4. Continue this process for each pair of adjacent elements until the end of the list.\n",
    "5. After each pass, the largest unsorted element is correctly placed at the end.\n",
    "6. **Repeat** these steps for the remaining list (excluding the last sorted elements).\n",
    "7. The sorting is complete when a pass requires no swaps.\n",
    "\n",
    "### Characteristics\n",
    "\n",
    "- **Time Complexity**:\n",
    "  - **Best Case**: $O(n)$ when the list is already sorted.\n",
    "  - **Worst Case**: $O(n^2)$ when the list is sorted in reverse order.\n",
    "- **Space Complexity**: $O(1)$, as it only requires a small, constant amount of additional space.\n",
    "- **Stability**: Bubble Sort is stable, meaning it preserves the order of equal elements.\n",
    "- **Adaptability**: It can adapt to a situation where the list is already sorted, making it efficient in such cases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.emre.me/sorting/bubble_sort.gif\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warm up task\n",
    "\n",
    "- Find a maximum value in a list\n",
    "- What steps would you take?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_maximum(arr):\n",
    "    pass\n",
    "\n",
    "# Example usage\n",
    "arr = [3, 6, 2, 8, 4]\n",
    "print(f\"Maximum number in the array is: {find_maximum(arr)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give an array of arbitrary length, find on what position lies a value\n",
    "# Assume array is of integers\n",
    "# if value is not found, return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_search(arr, x):\n",
    "    pass\n",
    "# Example usage\n",
    "arr = [3, 4, 1, 7, 9]\n",
    "x = 4\n",
    "print(f\"Element found at index: {linear_search(arr, x)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Search:\n",
    "\n",
    "Linear search is the simplest form of search:\n",
    "\n",
    "- You start at the first element of a list and check each item sequentially until you either find what you’re looking for or reach the end of the list.\n",
    "\n",
    "*Imagine searching for your friend in a crowd. If you don’t know where they are, you might start at one end of the crowd and look at each face one by one until you find them.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Complexity of Linear Search\n",
    "\n",
    "**Definition of Time Complexity:**\n",
    "\n",
    "Time complexity measures the number of operations an algorithm performs as a function of input size $n$. For linear search:\n",
    "\n",
    "- In the **worst case**, you have to look at every element once, so the complexity is $O(n)$.\n",
    "- In the **average case**, assuming the element is equally likely to be anywhere in the list, you’ll check $n/2$ elements on average. However, asymptotically, this still simplifies to $O(n)$.\n",
    "\n",
    "**Why Linear Search Can Be Inefficient:**\n",
    "\n",
    "As $n$ grows, the number of comparisons increases linearly. For small lists, this might not matter, but for large datasets—millions or billions of elements—linear search becomes impractical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Characteristics\n",
    "\n",
    "**Key Limitations:**\n",
    "\n",
    "Linear search doesn’t leverage any information about the structure of the data. Whether the data is sorted or unsorted, it treats all cases the same, performing a brute-force search.\n",
    "\n",
    "**When Is Linear Search Suitable?**\n",
    "\n",
    "- For small datasets, the simplicity of linear search makes it acceptable.\n",
    "- When the data is unsorted, linear search is often the only option unless you preprocess the data (e.g., sorting it for binary search)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question:\n",
    "\n",
    "- What is the complexity of searching in `m x n` matrix?\n",
    "\n",
    "### Can we devise a better algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Search\n",
    "\n",
    "Binary search is a fundamental algorithm that efficiently finds an element in a sorted list by repeatedly dividing the search space in half."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element found at index: None\n"
     ]
    }
   ],
   "source": [
    "def binary_search(arr, x):\n",
    "    pass\n",
    "\n",
    "# Example usage\n",
    "arr = [1, 3, 5, 7, 9]\n",
    "x = 1\n",
    "print(f\"Element found at index: {binary_search(arr, x)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Binary Search Works\n",
    "\n",
    "Imagine you have a dictionary, and you’re looking for the word “Python.” You don’t start from page 1 and flip through each page sequentially (linear search). Instead, you:\n",
    "\n",
    "1. Open the dictionary roughly in the middle.\n",
    "2. Compare the current page’s word with “Python.”\n",
    "    - If it comes **after**, you know “Python” must be in the latter half.\n",
    "    - If it comes **before**, you know it’s in the earlier half.\n",
    "3. Repeat this process, halving the search space each time, until you find the word.\n",
    "\n",
    "**Key Insight:**\n",
    "\n",
    "Each step eliminates **half of the remaining possibilities**, drastically reducing the number of comparisons.\n",
    "\n",
    "This intuitive approach highlights the precondition for binary search: **the data must be sorted**. Without this, the halving strategy wouldn’t work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Complexity: Why is Binary Search $O(\\log(n))$?\n",
    "\n",
    "**$O(\\log(⁡n))$,** assuming the data is sorted.\n",
    "\n",
    "1. Start with $n$ elements.\n",
    "2. After one comparison, half the elements are eliminated: $n \\to n/2$.\n",
    "3. After the second comparison: $n/2 \\to n/4$.\n",
    "4. This continues until only one element remains.\n",
    "\n",
    "Mathematically, the number of steps required is the number of times nn can be halved until it becomes 1:\n",
    "$$ log_2(n) $$\n",
    "\n",
    "This logarithmic relationship makes binary search exceptionally fast for large datasets. For example:\n",
    "\n",
    "- For $n=1,000,000$, binary search requires at most $\\log_2(1,000,000)≈20$ steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Characteristics\n",
    "\n",
    "1. **Worst-Case Scenario:**\n",
    "   - The element is at the far end of the search space, requiring $\\log_2(n)$ comparisons.\n",
    "   - Even in the worst case, the performance is exponentially better than linear search.\n",
    "\n",
    "2. **Average-Case Scenario:**\n",
    "    - On average, $\\log_2(n)$ comparisons are made because the search space is halved at each step.\n",
    "        \n",
    "3. **Best-Case Scenario:**\n",
    "    - The element is found in the first comparison: $O(1)$.\n",
    "\n",
    "**Why is Binary Search So Efficient?**\n",
    "\n",
    "Binary search minimizes the number of comparisons needed to locate an element. Even for massive datasets, the logarithmic growth ensures a small number of steps compared to the linear growth of comparisons in linear search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Efficiency Compared to Linear Search**\n",
    "\n",
    "Let’s break down the efficiency comparison in more detail:\n",
    "\n",
    "| **Aspect** | **Linear Search** | **Binary Search** |\n",
    "| --- | --- | --- |\n",
    "| **Time Complexity** | $O(n)$ | $O(\\log(⁡n))$ |\n",
    "| **Precondition** | Works on unsorted data | Requires sorted data |\n",
    "| **Performance on Small Data** | Good enough | Comparable, but requires sorting overhead |\n",
    "| **Performance on Large Data** | Slows down linearly as nn grows | Exponentially better as nn grows |\n",
    "\n",
    "**Key Observations:**\n",
    "\n",
    "1. **Dataset Size Dependency:**\n",
    "    - For $n=10,000$, linear search requires up to 10,000 comparisons, whereas binary search requires only about 14.\n",
    "2. **Precondition:**\n",
    "    - The requirement for sorted data is both a strength and a limitation. Sorting introduces overhead but enables much faster searches afterward.\n",
    "3. **Practical Implications:**\n",
    "    - For small datasets, linear search might suffice because the difference in speed is negligible. However, for large datasets, binary search becomes essential."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Real-World Implications**\n",
    "\n",
    "Binary search isn’t just theoretical; it’s widely used in real-world applications:\n",
    "\n",
    "- **Databases:** Efficient lookups in sorted tables.\n",
    "- **Search Engines:** Retrieving sorted documents quickly.\n",
    "- **Data Processing in Python:** Functions like `bisect` in Python’s standard library use binary search to find insertion points or locate elements in sorted lists.\n",
    "\n",
    "**Example with Python’s `bisect`:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "import bisect\n",
    "\n",
    "data = [1, 3, 5, 7, 9, 11]\n",
    "target = 7\n",
    "index = bisect.bisect_left(data, target)\n",
    "print(index)  # Output: 3 (index of 7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Intuitive Wrap-Up**\n",
    "\n",
    "1. Binary search is like cutting a big problem in half repeatedly until you isolate the solution.\n",
    "    - **Analogy:** Searching for a word in a dictionary or a number in a sorted phone book.\n",
    "2. Its logarithmic complexity ensures scalability for massive datasets, making it a cornerstone of algorithmic problem-solving.\n",
    "3. By understanding its limitations (requires sorted data) and strengths (exponential speedup), you can choose the right search method for any dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can We Devise a Better Algorithm?\n",
    "\n",
    "The short answer is **yes**, if we can leverage information about the structure of the data.\n",
    "\n",
    "### Key Insights for Better Algorithms:\n",
    "\n",
    "1. **Sorted Data:** Algorithms like binary search or staircase search exploit sorted structures to reduce the number of comparisons.\n",
    "2. **Hashing:** For searching large datasets, creating a hash table allows for $O(1)$ lookups at the cost of preprocessing time and memory.\n",
    "3. **Special Cases in Matrices:**\n",
    "    - For fully sorted matrices, staircase search is an optimal choice.\n",
    "    - For unsorted matrices, preprocessing (e.g., flattening and sorting the matrix) enables faster searching later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question: Searching in an $m×n$ Matrix\n",
    "\n",
    "The complexity of searching in an $m×n$ matrix depends on how the data is stored and structured.\n",
    "\n",
    "### **Case 1: Matrix as a Flat List (Unsorted)**\n",
    "\n",
    "If the matrix is treated as a large, flat list (or if each row is a separate list), and there’s no sorting:\n",
    "\n",
    "- You perform a **linear search** across $m×n$ elements.\n",
    "- **Time Complexity:** $O(m×n)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Case 2: Sorted Matrix**\n",
    "\n",
    "Suppose the matrix is sorted:\n",
    "\n",
    "1. **Row-Wise Sorted Only:**\n",
    "    - Searching within each row using linear search still gives $O(m×n)$.\n",
    "    - If we apply binary search to each row, the complexity becomes $O(m⋅log(n))$ (binary search on ncolumns for m rows).\n",
    "        \n",
    "2. **Fully Sorted Matrix:**\n",
    "    - Example: A matrix where both rows and columns are sorted.\n",
    "    - **Better Algorithm:** You can use a **staircase search** to achieve $O(m+n)$ complexity:\n",
    "        - Start from the top-right corner of the matrix.\n",
    "        - If the current element is larger than the target, move left.\n",
    "        - If it’s smaller, move down."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Python Code for Staircase Search:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def staircase_search(matrix, target):\n",
    "    \"\"\"\n",
    "    Perform a staircase search in a 2D matrix to find the target value.\n",
    "    The matrix must be sorted in ascending order both row-wise and column-wise.\n",
    "    The search starts from the top-right corner of the matrix and moves left or down\n",
    "    depending on the comparison with the target value.\n",
    "    Args:\n",
    "        matrix (list of list of int): 2D list where each sublist represents a row of the matrix.\n",
    "        target (int): The value to search for in the matrix.\n",
    "    Returns:\n",
    "        tuple: A tuple (row, col) representing the position of the target in the matrix.\n",
    "               Returns (-1, -1) if the target is not found.\n",
    "    \"\"\"\n",
    "    \n",
    "    rows = len(matrix)\n",
    "    cols = len(matrix[0])\n",
    "    row, col = 0, cols - 1  # Start at top-right corner\n",
    "\n",
    "    while row < rows and col >= 0:\n",
    "        if matrix[row][col] == target:\n",
    "            return row, col  # Found\n",
    "        elif matrix[row][col] > target:\n",
    "            col -= 1  # Move left\n",
    "        else:\n",
    "            row += 1  # Move down\n",
    "    return -1, -1  # Not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  3,  5],\n",
       "       [ 7,  9, 11],\n",
       "       [13, 15, 17]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a sorted 2D matrix\n",
    "matrix = [[1, 3, 5], [7, 9, 11], [13, 15, 17]]\n",
    "matrix = np.array(matrix)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Intuitive Wrap-Up**\n",
    "\n",
    "Let’s summarize with an analogy:\n",
    "\n",
    "- Linear search is like flipping through the pages of a book one by one to find a specific word. It’s straightforward but slow.\n",
    "- Optimized algorithms like binary search or staircase search are like using the table of contents or index to jump directly to the relevant section, saving significant time.\n",
    "\n",
    "This leads to a key takeaway: algorithmic thinking enables us to choose the right tool for the job, adapting our approach based on the structure and size of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find sum of all subarrays of size $k$ in an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_iteration(arr:list[int], k:int)->list[int]:\n",
    "    pass\n",
    "arr = [1,5,7,8,9,11]\n",
    "double_iteration(arr, 3) #O(n*k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_sliding_window(arr:list[int], k:int)->list[int]:\n",
    "    pass\n",
    "\n",
    "arr = [1,5,7,8,9,11] \n",
    "fixed_sliding_window(arr, 3)#O(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets compare the algorithms\n",
    "import random\n",
    "\n",
    "arr = [random.randint(0, 10000) for _ in range(1000)]\n",
    "k = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.8 ns ± 44.3 ns per loop (mean ± std. dev. of 10 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r 10 -n 10 double_iteration(arr, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.6 ns ± 63.3 ns per loop (mean ± std. dev. of 10 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r 10 -n 10 fixed_sliding_window(arr, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## imagine sliding windows with more complicated functions (mean, meadian) \n",
    "# create a structure which adds -> removes elements from the end and start of the window\n",
    "# idea is to always keep one pass through the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets get back to data processing level a bit\n",
    "\n",
    "### Lets try to make a small project of putting together a dataset of Tarantino movies from wikipedia\n",
    "\n",
    "- algorithmically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets prepare step by step what we will do "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# root_url = \"https://en.wikipedia.org\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of api request to openweather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       City  Temperature        Condition\n",
      "0  New York        16.69       few clouds\n",
      "1    London         7.56       light rain\n",
      "2     Tokyo         7.78  overcast clouds\n",
      "City with the highest temperature trend:\n",
      "       City  Temperature   Condition\n",
      "0  New York        16.69  few clouds\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Example list of cities\n",
    "cities = ['New York', 'London', 'Tokyo']\n",
    "# api_key = 'your key'\n",
    "\n",
    "weather_data = []\n",
    "\n",
    "# Step 1: Fetch data for each city\n",
    "for city in cities:\n",
    "    response = requests.get(f'https://api.openweathermap.org/data/2.5/weather?q={city}&appid={api_key}&units=metric')\n",
    "    data = response.json()\n",
    "    weather_data.append({\n",
    "        'City': city,\n",
    "        'Temperature': data['main']['temp'],\n",
    "        'Condition': data['weather'][0]['description']\n",
    "    })\n",
    "\n",
    "# Step 2: Convert to DataFrame for analysis\n",
    "df = pd.DataFrame(weather_data)\n",
    "\n",
    "# Step 3: Analyze the data\n",
    "highest_temp_city = df[df['Temperature'] == df['Temperature'].max()]\n",
    "print(df)\n",
    "print(\"City with the highest temperature trend:\")\n",
    "print(highest_temp_city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
